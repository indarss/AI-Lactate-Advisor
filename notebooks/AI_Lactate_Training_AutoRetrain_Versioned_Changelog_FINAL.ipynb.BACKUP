{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4811109",
   "metadata": {},
   "source": [
    "# ğŸ§  AI Lactate Advisor â€“ Final Training Notebook (Merged & Clean)\n",
    "\n",
    "This notebook trains and versions two models:\n",
    "\n",
    "1. **Lactate Model** â€“ predicts blood lactate (mmol/L) from time-series features  \n",
    "2. **Recovery Model** â€“ predicts recovery/readiness score from biomarker data  \n",
    "\n",
    "It is designed to be consistent with the **Streamlit app**, saving models into `models/`\n",
    "and appending results to `models/training_log.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a670181",
   "metadata": {},
   "source": [
    "## ğŸ“— Cell 1 â€” Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# ğŸ“˜ Cell 1 â€” Imports & Global Config\n",
    "# =============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "from github import Github\n",
    "\n",
    "# model_utils functions\n",
    "from model_utils import (\n",
    "    prepare_features,\n",
    "    add_hr_slopes,\n",
    "    add_rolling_features,\n",
    ")\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "MODELS_DIR = \"models\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Model output paths (latest versions)\n",
    "LACTATE_MODEL_PATH = os.path.join(MODELS_DIR, \"lactate_lightgbm_model.joblib\")\n",
    "RECOVERY_MODEL_PATH = os.path.join(MODELS_DIR, \"recovery_lightgbm_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0782c99",
   "metadata": {},
   "source": [
    "## ğŸ“— Cell 2 â€” Load & Merge New Data Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# ğŸ“— Cell 2 â€” Auto-detect NEW CSVs and merge into master dataset\n",
    "# =============================================================\n",
    "\n",
    "MASTER_DATASET = os.path.join(DATA_DIR, \"athlete_training_dataset_with_biomarkers.csv\")\n",
    "\n",
    "# Find all CSVs in /data\n",
    "csv_files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".csv\")]\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"âŒ No CSV files found in /data folder.\")\n",
    "\n",
    "# Newest file\n",
    "latest_file = max(csv_files, key=lambda f: os.path.getmtime(os.path.join(DATA_DIR, f)))\n",
    "latest_path = os.path.join(DATA_DIR, latest_file)\n",
    "\n",
    "print(\"ğŸ“„ Latest detected dataset:\", latest_file)\n",
    "\n",
    "# Load master dataset\n",
    "if os.path.exists(MASTER_DATASET):\n",
    "    df_master = pd.read_csv(MASTER_DATASET)\n",
    "    master_mtime = os.path.getmtime(MASTER_DATASET)\n",
    "else:\n",
    "    df_master = pd.DataFrame()\n",
    "    master_mtime = 0\n",
    "\n",
    "# Compare timestamps\n",
    "latest_mtime = os.path.getmtime(latest_path)\n",
    "\n",
    "if latest_mtime > master_mtime:\n",
    "    print(\"ğŸ“¦ New dataset detected â€” merging into master file.\")\n",
    "    df_new = pd.read_csv(latest_path)\n",
    "\n",
    "    if not df_master.empty:\n",
    "        df_merged = pd.concat([df_master, df_new], ignore_index=True).drop_duplicates()\n",
    "    else:\n",
    "        df_merged = df_new\n",
    "\n",
    "    df_merged.to_csv(MASTER_DATASET, index=False)\n",
    "    df = df_merged\n",
    "    retrain_required = True\n",
    "else:\n",
    "    print(\"âœ… No new data â€” loading current master file.\")\n",
    "    df = pd.read_csv(MASTER_DATASET)\n",
    "    retrain_required = False\n",
    "\n",
    "print(\"ğŸ“Š Final dataset shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb5dbd",
   "metadata": {},
   "source": [
    "##  ğŸ“— Cell 3 â€” Feature Preparation (Lactate + Recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# ğŸ“— Cell 3 â€” Feature Engineering for Lactate & Recovery Models\n",
    "# =============================================================\n",
    "\n",
    "assert 'lactate' in df.columns, \"âŒ Missing 'lactate' column in merged dataset!\"\n",
    "assert 'recovery_score' in df.columns, \"âŒ Missing 'recovery_score' column!\"\n",
    "\n",
    "# Add engineered features\n",
    "df_feat = df.copy()\n",
    "df_feat = add_hr_slopes(df_feat)\n",
    "df_feat = add_rolling_features(df_feat, window=30)\n",
    "\n",
    "# -------- Lactate Data --------\n",
    "X_lac = prepare_features(df_feat)\n",
    "y_lac = df_feat['lactate']\n",
    "\n",
    "print(\"Lactate features:\", X_lac.shape)\n",
    "\n",
    "# -------- Recovery Data --------\n",
    "recovery_cols = ['heart_rate', 'power', 'cadence', 'hr_slope_time']\n",
    "\n",
    "X_rec = df_feat[recovery_cols].copy()\n",
    "y_rec = df_feat['recovery_score']\n",
    "\n",
    "print(\"Recovery features:\", X_rec.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c0d4a6",
   "metadata": {},
   "source": [
    "## ğŸ“— Cell 4 â€” Model Training (Lactate + Recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dafc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# ğŸ“— Cell 4 â€” Train/Test Split + Model Training\n",
    "# =============================================================\n",
    "\n",
    "def train_lightgbm_model(X, y, model_name):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"ğŸš€ Training {model_name} ...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Embedding feature schema\n",
    "    model.feature_names_in_ = list(X.columns)\n",
    "\n",
    "    # Validation\n",
    "    y_pred = model.predict(X_val)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "    print(f\"ğŸ“ˆ {model_name} â€” R2={r2:.3f}, MAE={mae:.3f}\")\n",
    "\n",
    "    return model, r2, mae\n",
    "\n",
    "# Train Lactate\n",
    "lactate_model, r2_lac, mae_lac = train_lightgbm_model(X_lac, y_lac, \"lactate\")\n",
    "\n",
    "# Train Recovery\n",
    "recovery_model, r2_rec, mae_rec = train_lightgbm_model(X_rec, y_rec, \"recovery\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989f42d",
   "metadata": {},
   "source": [
    "## ğŸ“— Cell 5 â€” Save Models + Version + Log Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# ğŸ“— Cell 5 â€” Save Models + Versioning + Log Training Metrics\n",
    "# =============================================================\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save latest\n",
    "joblib.dump(lactate_model, LACTATE_MODEL_PATH)\n",
    "joblib.dump(recovery_model, RECOVERY_MODEL_PATH)\n",
    "\n",
    "# Save versioned\n",
    "joblib.dump(lactate_model, f\"{MODELS_DIR}/lactate_lightgbm_{timestamp}.joblib\")\n",
    "joblib.dump(recovery_model, f\"{MODELS_DIR}/recovery_lightgbm_{timestamp}.joblib\")\n",
    "\n",
    "print(\"ğŸ’¾ Models saved.\")\n",
    "\n",
    "# ---- Append training log ----\n",
    "log_path = os.path.join(MODELS_DIR, \"training_log.csv\")\n",
    "\n",
    "log_entry = pd.DataFrame([{\n",
    "    \"timestamp\": timestamp,\n",
    "    \"r2_lactate\": r2_lac,\n",
    "    \"mae_lactate\": mae_lac,\n",
    "    \"r2_recovery\": r2_rec,\n",
    "    \"mae_recovery\": mae_rec,\n",
    "    \"rows\": len(df)\n",
    "}])\n",
    "\n",
    "if os.path.exists(log_path):\n",
    "    log_entry.to_csv(log_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    log_entry.to_csv(log_path, index=False)\n",
    "\n",
    "print(\"ğŸ“˜ Training metrics logged to training_log.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
