{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4811109",
   "metadata": {},
   "source": [
    "# üß† AI Lactate Advisor - AutoRetrain Versioned Notebook (Updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üìä DATA PREPARATION (Lactate Features & Labels)\n",
    "# =============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Download model_utils.py from GitHub\n",
    "!wget -q -O model_utils.py https://raw.githubusercontent.com/indarss/AI-Lactate-Advisor/main/model_utils.py\n",
    "# Install required libraries\n",
    "%pip install -q streamlit\n",
    "\n",
    "from model_utils import make_features, prepare_features\n",
    "\n",
    "# Load your training dataset\n",
    "# Adjust the path if your data is in a different location\n",
    "df = pd.read_csv('/content/data/athlete_training_dataset.csv')  # or your dataset path\n",
    "\n",
    "print(f\"‚úÖ Loaded data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# === Prepare features and labels ===\n",
    "# Assuming 'lactate' column exists in your dataset\n",
    "assert 'lactate' in df.columns, \"Dataset must contain 'lactate' column\"\n",
    "\n",
    "# Prepare features, which may drop rows due to NaN values in feature engineering\n",
    "processed_features_df = prepare_features(df)\n",
    "\n",
    "# Align y with the processed features X using the index of processed_features_df\n",
    "X_temp = processed_features_df\n",
    "y_temp = df.loc[X_temp.index, 'lactate'] # Get as Series to easily drop NaNs\n",
    "\n",
    "# Drop rows where y_temp is NaN, ensuring X and y are perfectly aligned and clean\n",
    "nan_mask = y_temp.isna()\n",
    "X = X_temp[~nan_mask]\n",
    "y = y_temp[~nan_mask].values\n",
    "\n",
    "print(f\"‚úÖ Features prepared: X shape = {X.shape}\")\n",
    "print(f\"‚úÖ Labels prepared: y shape = {y.shape}\")\n",
    "print(f\"üìã Feature columns: {list(X.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üìä Train/Validation Split for Lactate Model\n",
    "# =============================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X and y must already be defined in the data preparation cell\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training features:\", X_train.shape)\n",
    "print(\"Validation features:\", X_val.shape)\n",
    "print(\"Training labels:\", y_train.shape)\n",
    "print(\"Validation labels:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a670181",
   "metadata": {},
   "source": [
    "This notebook includes automatic retraining logic for both **Lactate** and **Recovery** models, including versioning, feature name storage, and optional GitHub uploads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0782c99",
   "metadata": {},
   "source": [
    "## üöÄ Added: LightGBM Training Cells for Lactate and Recovery Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ca2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================\n",
    "# üöÄ TRAINING CELL (Lactate Model + Auto-Save + Optional GitHub)\n",
    "# =============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import joblib, os\n",
    "from datetime import datetime\n",
    "\n",
    "# === Prepare splits ===\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "print(f\"‚úÖ Data split: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}\")\n",
    "\n",
    "# === Train model ===\n",
    "params = {\n",
    "    \"n_estimators\": 400,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "print(\"üöÄ Training LightGBM Lactate Model...\")\n",
    "model = LGBMRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_val = model.predict(X_val)\n",
    "r2 = r2_score(y_val, y_pred_val)\n",
    "mae = mean_absolute_error(y_val, y_pred_val)\n",
    "print(f\"üìà Validation R¬≤ = {r2:.3f}, MAE = {mae:.3f}\")\n",
    "\n",
    "# === Save ===\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "latest_path = os.path.join(MODEL_DIR, \"lactate_lightgbm_model.joblib\")\n",
    "versioned_path = os.path.join(MODEL_DIR, f\"lactate_lightgbm_model_{timestamp}.joblib\")\n",
    "\n",
    "joblib.dump(model, latest_path)\n",
    "joblib.dump(model, versioned_path)\n",
    "print(f\"üíæ Models saved:\\n ‚î£‚îÅ {latest_path}\\n ‚îó‚îÅ {versioned_path}\")\n",
    "\n",
    "# Store feature names for compatibility\n",
    "model.feature_names_in_ = list(X_train.columns)\n",
    "# The LightGBM model automatically stores feature names when fitted with a DataFrame.\n",
    "# Explicitly assigning to .feature_names_in_ is not needed and causes an AttributeError.\n",
    "# You can access them via model.feature_name_ if needed later.\n",
    "print(f\"üß© Stored {len(model.feature_names_in_)} feature names for alignment.\")\n",
    "\n",
    "# === Optional: GitHub Upload ===\n",
    "GITHUB_USERNAME = \"indarss\"\n",
    "GITHUB_REPO = \"AI-Lactate-Advisor\"\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")  # Set this in Colab: Runtime ‚Üí Secrets\n",
    "\n",
    "if GITHUB_TOKEN:\n",
    "    try:\n",
    "        from github import Github\n",
    "        g = Github(GITHUB_TOKEN)\n",
    "        repo = g.get_user().get_repo(GITHUB_REPO)\n",
    "\n",
    "        def upload_or_update(local_path, repo_path, message):\n",
    "            with open(local_path, \"rb\") as f:\n",
    "                content = f.read()\n",
    "            try:\n",
    "                existing = repo.get_contents(repo_path)\n",
    "                repo.update_file(existing.path, message, content, existing.sha, branch=\"main\")\n",
    "                print(f\"‚úÖ Updated on GitHub: {repo_path}\")\n",
    "            except Exception:\n",
    "                repo.create_file(repo_path, message, content, branch=\"main\")\n",
    "                print(f\"‚úÖ Uploaded new file: {repo_path}\")\n",
    "\n",
    "        upload_or_update(latest_path, f\"models/lactate_lightgbm_model.joblib\", \"Auto-update lactate model\")\n",
    "        upload_or_update(versioned_path, f\"models/lactate_lightgbm_model_{timestamp}.joblib\", \"Auto-version lactate model\")\n",
    "        print(\"üåê GitHub upload complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è GitHub upload failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GITHUB_TOKEN not set ‚Äî skipping GitHub upload.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d19d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================\n",
    "# üß¨ TRAINING CELL (Recovery Model + Biomarker Data)\n",
    "# =============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import joblib, os\n",
    "from datetime import datetime\n",
    "\n",
    "# Load biomarker dataset (ensure it's preloaded as df_rec or similar)\n",
    "if 'df_rec' not in globals():\n",
    "    df_rec = pd.read_csv('data/athlete_training_dataset_with_biomarkers.csv')\n",
    "\n",
    "assert 'recovery_score' in df_rec.columns, \"Biomarker dataset must contain 'recovery_score' column.\"\n",
    "Xr = df_rec.drop(columns=['recovery_score'])\n",
    "yr = df_rec['recovery_score']\n",
    "\n",
    "# Split data\n",
    "Xr_train_full, Xr_test, yr_train_full, yr_test = train_test_split(Xr, yr, test_size=0.2, random_state=42)\n",
    "Xr_train, Xr_val, yr_train, yr_val = train_test_split(Xr_train_full, yr_train_full, test_size=0.25, random_state=42)\n",
    "print(f\"‚úÖ Data split: Train={len(Xr_train)}, Val={len(Xr_val)}, Test={len(Xr_test)}\")\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 400,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "print(\"üöÄ Training LightGBM Recovery Model...\")\n",
    "recovery_model = LGBMRegressor(**params)\n",
    "recovery_model.fit(Xr_train, yr_train)\n",
    "\n",
    "# Evaluate\n",
    "yr_pred_val = recovery_model.predict(Xr_val)\n",
    "r2 = r2_score(yr_val, yr_pred_val)\n",
    "mae = mean_absolute_error(yr_val, yr_pred_val)\n",
    "print(f\"üìà Validation R¬≤ = {r2:.3f}, MAE = {mae:.3f}\")\n",
    "\n",
    "# Save model\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "latest_path = os.path.join(MODEL_DIR, \"recovery_lightgbm_model.joblib\")\n",
    "versioned_path = os.path.join(MODEL_DIR, f\"recovery_lightgbm_model_{timestamp}.joblib\")\n",
    "\n",
    "joblib.dump(recovery_model, latest_path)\n",
    "joblib.dump(recovery_model, versioned_path)\n",
    "print(f\"üíæ Models saved:\\n ‚î£‚îÅ {latest_path}\\n ‚îó‚îÅ {versioned_path}\")\n",
    "\n",
    "# Store feature names\n",
    "# recovery_model.feature_names_in_ = list(Xr_train.columns)\n",
    "#print(f\"üß© Stored {len(recovery_model.feature_names_in_)} feature names for alignment.\")\n",
    "# Store feature names - Not needed, LightGBM handles this automatically\n",
    "print(f\"üß© Stored {len(Xr_train.columns)} feature names for alignment.\")\n",
    "\n",
    "# Optional GitHub upload\n",
    "if GITHUB_TOKEN:\n",
    "    try:\n",
    "        from github import Github\n",
    "        g = Github(GITHUB_TOKEN)\n",
    "        repo = g.get_user().get_repo(GITHUB_REPO)\n",
    "\n",
    "        def upload_or_update(local_path, repo_path, message):\n",
    "            with open(local_path, \"rb\") as f:\n",
    "                content = f.read()\n",
    "            try:\n",
    "                existing = repo.get_contents(repo_path)\n",
    "                repo.update_file(existing.path, message, content, existing.sha, branch=\"main\")\n",
    "                print(f\"‚úÖ Updated on GitHub: {repo_path}\")\n",
    "            except Exception:\n",
    "                repo.create_file(repo_path, message, content, branch=\"main\")\n",
    "                print(f\"‚úÖ Uploaded new file: {repo_path}\")\n",
    "\n",
    "        upload_or_update(latest_path, f\"models/recovery_lightgbm_model.joblib\", \"Auto-update recovery model\")\n",
    "        upload_or_update(versioned_path, f\"models/recovery_lightgbm_model_{timestamp}.joblib\", \"Auto-version recovery model\")\n",
    "        print(\"üåê GitHub upload complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è GitHub upload failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GITHUB_TOKEN not set ‚Äî skipping GitHub upload.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb5dbd",
   "metadata": {},
   "source": [
    "## üìä Combined Metrics Summary (Lactate & Recovery Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================\n",
    "# üìä Combined Metrics Summary (Test Set)\n",
    "# Recomputes R¬≤ / MAE for both models on held-out test sets\n",
    "# =============================================\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "rows = []\n",
    "\n",
    "# ---- Lactate model metrics on test ----\n",
    "try:\n",
    "    y_pred_test_lac = model.predict(X_test)\n",
    "    r2_lac = r2_score(y_test, y_pred_test_lac)\n",
    "    mae_lac = mean_absolute_error(y_test, y_pred_test_lac)\n",
    "    rows.append({\"Model\": \"Lactate (LightGBM)\", \"R2 (test)\": r2_lac, \"MAE (test)\": mae_lac, \"n_test\": len(X_test)})\n",
    "except Exception as e:\n",
    "    rows.append({\"Model\": \"Lactate (LightGBM)\", \"R2 (test)\": None, \"MAE (test)\": None, \"n_test\": 0})\n",
    "    print(f\"‚ö†Ô∏è Could not compute lactate test metrics: {e}\")\n",
    "\n",
    "# ---- Recovery model metrics on test ----\n",
    "try:\n",
    "    y_pred_test_rec = recovery_model.predict(Xr_test)\n",
    "    r2_rec = r2_score(yr_test, y_pred_test_rec)\n",
    "    mae_rec = mean_absolute_error(yr_test, y_pred_test_rec)\n",
    "    rows.append({\"Model\": \"Recovery (LightGBM)\", \"R2 (test)\": r2_rec, \"MAE (test)\": mae_rec, \"n_test\": len(Xr_test)})\n",
    "except Exception as e:\n",
    "    rows.append({\"Model\": \"Recovery (LightGBM)\", \"R2 (test)\": None, \"MAE (test)\": None, \"n_test\": 0})\n",
    "    print(f\"‚ö†Ô∏è Could not compute recovery test metrics: {e}\")\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "display(df_metrics.style.format({\"R2 (test)\": \"{:.3f}\", \"MAE (test)\": \"{:.3f}\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c0d4a6",
   "metadata": {},
   "source": [
    "## üßæ Save Training Metrics to CSV Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================================================\n",
    "# üßæ Save Training Metrics to models/training_log.csv\n",
    "# =====================================================\n",
    "import csv, os\n",
    "from datetime import datetime\n",
    "\n",
    "LOG_PATH = os.path.join(\"models\", \"training_log.csv\")\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "rows_to_log = []\n",
    "\n",
    "if 'r2_lac' in locals():\n",
    "    rows_to_log.append([\"lactate\", timestamp, r2_lac, mae_lac, len(X_test)])\n",
    "if 'r2_rec' in locals():\n",
    "    rows_to_log.append([\"recovery\", timestamp, r2_rec, mae_rec, len(Xr_test)])\n",
    "\n",
    "header = [\"model\", \"timestamp\", \"r2_test\", \"mae_test\", \"n_test\"]\n",
    "\n",
    "file_exists = os.path.exists(LOG_PATH)\n",
    "with open(LOG_PATH, \"a\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    if not file_exists:\n",
    "        writer.writerow(header)\n",
    "    writer.writerows(rows_to_log)\n",
    "\n",
    "print(f\"‚úÖ Logged {len(rows_to_log)} entries to {LOG_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
