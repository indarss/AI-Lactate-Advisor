{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udde0 Train Recovery Estimator (LightGBM)\n",
        "\n",
        "This notebook trains a **LightGBM regression model** to predict `recovery_score` from biomarkers.\n",
        "\n",
        "### What you'll get\n",
        "- Auto-detect & load dataset (sample or your real CSV)\n",
        "- Train/validate LightGBM model\n",
        "- Evaluate (R\u00b2, MAE) and plot predictions vs truth\n",
        "- **Compare AI model vs rule-based score**\n",
        "- Optional **SHAP** feature importance plots\n",
        "- Save model \u2192 `models/recovery_lightgbm_model.joblib`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "import os, sys, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure project root on sys.path\n",
        "repo_root = Path.cwd()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.append(str(repo_root))\n",
        "\n",
        "print('Working dir:', repo_root)\n",
        "print('Listing files:', [p.name for p in repo_root.iterdir()][:15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load dataset (auto-detect)\n",
        "Looks for `data/athlete_training_dataset_with_biomarkers_SAMPLE.csv` first, then root.\n",
        "Required columns: `ck, cortisol, tc_ratio, hscrp, glucose, rbc, recovery_score`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load_data"
      },
      "source": [
        "candidates = [\n",
        "    Path('data/athlete_training_dataset_with_biomarkers_SAMPLE.csv'),\n",
        "    Path('athlete_training_dataset_with_biomarkers_SAMPLE.csv'),\n",
        "    Path('athlete_training_dataset_with_biomarkers.csv'),\n",
        "]\n",
        "csv_path = None\n",
        "for c in candidates:\n",
        "    if c.exists():\n",
        "        csv_path = c; break\n",
        "\n",
        "if csv_path is None:\n",
        "    raise FileNotFoundError('No dataset found. Please upload a CSV with biomarkers + recovery_score.')\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print('\u2705 Loaded:', csv_path)\n",
        "print(df.head())\n",
        "print('Shape:', df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Train/Validation split & LightGBM training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "train"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from lightgbm import LGBMRegressor\n",
        "import joblib\n",
        "\n",
        "feature_cols = ['ck','cortisol','tc_ratio','hscrp','glucose','rbc']\n",
        "target_col = 'recovery_score'\n",
        "\n",
        "for col in feature_cols + [target_col]:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f'Missing required column: {col}')\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[target_col].astype(float)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LGBMRegressor(n_estimators=400, learning_rate=0.05, max_depth=-1, subsample=0.9, colsample_bytree=0.9, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "r2 = r2_score(y_test, pred_test)\n",
        "mae = mean_absolute_error(y_test, pred_test)\n",
        "print(f'R\u00b2: {r2:.3f}  |  MAE: {mae:.2f}')\n",
        "\n",
        "# Save model\n",
        "models_dir = Path('models'); models_dir.mkdir(exist_ok=True)\n",
        "out_path = models_dir / 'recovery_lightgbm_model.joblib'\n",
        "joblib.dump(model, out_path)\n",
        "print('\ud83d\udcbe Saved model to', out_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Plot predictions vs truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plots"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, pred_test, alpha=0.5)\n",
        "plt.plot([0,100],[0,100],'k--', lw=1)\n",
        "plt.title('Recovery: Predictions vs Truth')\n",
        "plt.xlabel('True Recovery Score')\n",
        "plt.ylabel('Predicted Recovery Score')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Compare with rule-based score\n",
        "We recreate the simple handcrafted score and compare against model predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rule_compare"
      },
      "source": [
        "# Rule-based score (as used earlier)\n",
        "def rule_based_score(row):\n",
        "    score = 100 - (\n",
        "        (row['ck'] - 100) * 0.05 +\n",
        "        (row['cortisol'] - 250) * 0.03 +\n",
        "        (row['hscrp'] - 0.5) * 10 +\n",
        "        (1 - row['tc_ratio']) * 20\n",
        "    )\n",
        "    return np.clip(score, 0, 100)\n",
        "\n",
        "rb = X_test.copy()\n",
        "rb['rule_score'] = X_test.apply(rule_based_score, axis=1)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "rb_mae = mean_absolute_error(y_test, rb['rule_score'])\n",
        "rb_r2  = r2_score(y_test, rb['rule_score'])\n",
        "print(f'Rule-based \u2014 R\u00b2: {rb_r2:.3f}  |  MAE: {rb_mae:.2f}')\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, rb['rule_score'], alpha=0.5, label='Rule-based')\n",
        "plt.scatter(y_test, pred_test, alpha=0.5, label='LightGBM')\n",
        "plt.plot([0,100],[0,100],'k--', lw=1)\n",
        "plt.title('Model vs Rule-based Recovery')\n",
        "plt.xlabel('True Recovery Score')\n",
        "plt.ylabel('Predicted Score')\n",
        "plt.legend(); plt.grid(alpha=0.3)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) SHAP interpretation (optional)\n",
        "If `shap` is installed, plot global feature importance and contribution summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shap"
      },
      "source": [
        "try:\n",
        "    import shap\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    # Use a smaller sample for speed\n",
        "    Xs = X_test.sample(min(512, len(X_test)), random_state=42)\n",
        "    sv = explainer.shap_values(Xs)\n",
        "    shap.summary_plot(sv, Xs, show=True)\n",
        "except Exception as e:\n",
        "    print('SHAP not available or failed:', e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Save evaluation table to CSV\n",
        "Useful for reporting or for your Streamlit demo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "save_csv"
      },
      "source": [
        "results = pd.DataFrame({\n",
        "    'true': y_test.reset_index(drop=True),\n",
        "    'pred_lightgbm': pred_test,\n",
        "    'pred_rule_based': rb['rule_score'].reset_index(drop=True)\n",
        "})\n",
        "out_csv = Path('/content/recovery_eval_results.csv')\n",
        "results.to_csv(out_csv, index=False)\n",
        "print('\ud83d\udcbe Saved:', out_csv)\n",
        "results.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) (Optional) Push model to GitHub\n",
        "Configure a GitHub Personal Access Token (classic, `repo` scope) in a Colab secret before running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "github_optional"
      },
      "source": [
        "import os, base64, json, requests\n",
        "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')  # set in Colab: %env GITHUB_TOKEN=xxxx\n",
        "REPO = 'indarss/AI-Lactate-Advisor'\n",
        "BRANCH = 'main'\n",
        "TARGET_PATH = 'models/recovery_lightgbm_model.joblib'\n",
        "\n",
        "if GITHUB_TOKEN:\n",
        "    with open('models/recovery_lightgbm_model.joblib', 'rb') as f:\n",
        "        content = base64.b64encode(f.read()).decode('utf-8')\n",
        "\n",
        "    url = f'https://api.github.com/repos/{REPO}/contents/{TARGET_PATH}'\n",
        "    headers = {'Authorization': f'token {GITHUB_TOKEN}', 'Accept': 'application/vnd.github+json'}\n",
        "    data = {\n",
        "        'message': 'Add recovery LightGBM model (auto-upload)',\n",
        "        'content': content,\n",
        "        'branch': BRANCH\n",
        "    }\n",
        "    r = requests.put(url, headers=headers, data=json.dumps(data))\n",
        "    print('GitHub upload status:', r.status_code)\n",
        "    print(r.text[:500])\n",
        "else:\n",
        "    print('Skipping GitHub upload (no GITHUB_TOKEN set).')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}